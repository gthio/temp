{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@datalesdatales/why-you-should-be-plotting-learning-curves-in-your-next-machine-learning-project-221bae60c53\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Problem formulation\n",
    " ---\n",
    "\n",
    " This notebook contains detail work on building machine learning model(s) to predict house's sale price in Ames, Iowa. The model is build based on historical sale price with its 79 explanatory attributes like house area, lot size, house's condition, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Context\n",
    " ---\n",
    " Dataset covers house sale price in Ames - Iowa, from January 2006 to July 2010, with its 79 explanatory attributes describing every feature every feature of homes.\n",
    "\n",
    "\n",
    " **Data sources**\n",
    " * **train.csv** - training dataset\n",
    " * **test.csv** - test dataset\n",
    " * **data_description.txt** - dataset's metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Development environment setup\n",
    " ---\n",
    "\n",
    " 1. Import packages\n",
    "     * numpy, scipy, pandas, matplotlib + seaborn\n",
    "     * sklearn\n",
    " 2. Set common configurations\n",
    "     * dataframe's options\n",
    "     * matplotlib, seaborn style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.style as style\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# sklearn's pre-processing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# sklearn's feature selection\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# sklearn's model and metrics\n",
    "from sklearn.model_selection import train_test_split, cross_validate, learning_curve, GridSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dataframe display options\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "    \n",
    "#set pyplot and seaborn style\n",
    "sns.set(style=\"whitegrid\", palette=\"deep\", color_codes=True)\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Common custom functions\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe meta data\n",
    "\n",
    "def get_meta_data(df):\n",
    "    \n",
    "    # get column's datatype\n",
    "    temp1 = pd.DataFrame({'dtype': df.dtypes}).T\n",
    "\n",
    "    # get column's description\n",
    "    temp2 = df.describe(include='all')\n",
    "\n",
    "    # combine all\n",
    "    temp = pd.concat([temp1, temp2]).T\n",
    "\n",
    "    return temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get missing data info for each attribute\n",
    "\n",
    "def get_stat_null(x, df_data):\n",
    "    \n",
    "    col = x.name\n",
    "    count_null = df_data[col].isnull().sum()\n",
    "    count_notnull = df_data[col].notnull().sum()\n",
    "    pct_null = count_null / (count_null + count_notnull)\n",
    "\n",
    "    return [count_notnull, count_null, pct_null]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get each attribute's uniqueness data\n",
    "\n",
    "def get_stat_uniqueness(x, df_data):\n",
    "    \n",
    "    col = x.name\n",
    "    count = len(df_data[col].dropna())\n",
    "    uniques = df_data[col].dropna().unique()\n",
    "    \n",
    "    flatten = '...'\n",
    "    unique_count = len(uniques) #float('nan')\n",
    "    \n",
    "    if (unique_count < 16):\n",
    "        flatten = ', '.join([str(x) for x in uniques if ((x is not ''))])\n",
    "        unique_count = len(uniques)\n",
    "\n",
    "    return [unique_count, flatten]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get each attribute's statistic value (ie. skew and kurtosis)\n",
    "\n",
    "def get_stat(x, df_data):\n",
    "    \n",
    "    col = x.name\n",
    "    \n",
    "    skewness = float('nan')\n",
    "    kurtosis = float('nan')\n",
    "\n",
    "    if ((x['dtype'] == 'int64') | (x['dtype'] == 'float64')):\n",
    "        skewness = df_data[col].skew()\n",
    "        kurtosis = df_data[col].kurtosis()\n",
    "        \n",
    "    return [skewness, kurtosis]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe stat (metadata)\n",
    "\n",
    "def get_dataframe_metadata(df):\n",
    "    \n",
    "    # get and set dataframe's metadata\n",
    "    df_meta = get_meta_data(df)\n",
    "\n",
    "    # set stat info for each attribute\n",
    "    set_stat(df, df_meta)\n",
    "\n",
    "    return df_meta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get each attribute's 3rd, 2nd and 1st quartile deviation\n",
    "\n",
    "def get_stat_quart(x):\n",
    "    \n",
    "    col = x.name\n",
    "    \n",
    "    upper1 = float('nan'); lower1 = float('nan')\n",
    "    upper2 = float('nan'); lower2 = float('nan')\n",
    "    upper3 = float('nan'); lower3 = float('nan')    \n",
    "\n",
    "    if ((x['dtype'] == 'int64') | (x['dtype'] == 'float64')):\n",
    "        mean = x['mean']\n",
    "        stddev = x['std']\n",
    "\n",
    "        lower3 = mean - (stddev * 3); upper3 = mean + (stddev * 3)\n",
    "        lower2 = mean - (stddev * 2); upper2 = mean + (stddev * 2)        \n",
    "        lower1 = mean - (stddev * 1); upper1 = mean + (stddev * 1)        \n",
    "        \n",
    "    return [lower1, upper1, lower2, upper2, lower3, upper3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set each attribute's stats\n",
    "\n",
    "def set_stat(df_data, df_meta):\n",
    "    \n",
    "    # set missing data info for each attribute\n",
    "    df_meta[['notnull_count', 'null_count', 'null_pct']] = df_meta.loc[:, :].apply(\n",
    "        lambda x: get_stat_null(x, df_data), axis=1, result_type=\"expand\")\n",
    "\n",
    "    # set each attribute's uniqueness data\n",
    "    df_meta[['unique_count', 'unique_values']] = df_meta.loc[:, :].apply(\n",
    "        lambda x: get_stat_uniqueness(x, df_data), axis=1, result_type=\"expand\")\n",
    "\n",
    "    # set each attribute's statistic value (ie. skew and kurtosis)\n",
    "    df_meta[['skew', 'kurtosis']] = df_meta.loc[:, :].apply(\n",
    "        lambda x: get_stat(x, df_data), axis=1, result_type=\"expand\")\n",
    "\n",
    "    # set each attribute's 3rd, 2nd and 1st quartile deviation\n",
    "    df_meta[['lower_3s_1', 'upper_3s_1', \n",
    "             'lower_3s_2', 'upper_3s_2', \n",
    "             'lower_3s_3', 'upper_3s_3']] = df_meta.loc[:, :].apply(\n",
    "        lambda x: get_stat_quart(x), axis=1, result_type=\"expand\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation\n",
    "\n",
    "def compute_correlation_matrix(df, target, attributes):\n",
    "    \n",
    "    # compute correlation matrix\n",
    "    df_corr = df[target+attributes].corr()\n",
    "    \n",
    "    # order by correlation to target, descending \n",
    "    temp1 = df_corr.iloc[:, :].sort_values(by=target, ascending=False)\n",
    "    \n",
    "    # get features list - to reorder columns\n",
    "    temp2 = temp1.iloc[:, 0].index[:]\n",
    "    \n",
    "    result = temp1.loc[:, temp2]\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot pca - 1D\n",
    "\n",
    "def plot_pca(df, target, attributes):\n",
    "    \n",
    "    target_string = target[0]\n",
    "    \n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(df[attributes])\n",
    "    cols_1d = pca.transform(df[attributes])\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(cols_1d, df[target])\n",
    "    ax.set_title('1D PCA plot (selected ' + str(len(attributes)) + ' attributes)')\n",
    "    ax.set_xlabel('cols 1d')\n",
    "    ax.set_ylabel(target_string)\n",
    "    plt.show()\n",
    "    \n",
    "    x = pd.DataFrame({target_string: df[target_string], 'cols_1d' : cols_1d.flatten()}).corr()\n",
    "    \n",
    "    print(x)    \n",
    "    \n",
    "    return cols_1d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot target to features 1-d pca\n",
    "\n",
    "def plot_pca_smarter(df, df_meta, target, number_of_attributes):\n",
    "\n",
    "\n",
    "    attributes = df_meta.loc[(np.in1d(df_meta.dtype, dtype_numeric)) & (df_meta['null_count'] == 0)][1:number_of_attributes].index\n",
    "\n",
    "    cols_1d = plot_pca(df, target, attributes)\n",
    "    \n",
    "def plot_pca_smarter2(df, df_meta, target, attributes):\n",
    "\n",
    "    cols_1d = plot_pca(df, target, attributes)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlations\n",
    "\n",
    "def plot_correlation_matrix(df_corr):\n",
    "    \n",
    "    mask = np.zeros_like(df_corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(20, 20))\n",
    "    sns.heatmap(df_corr, linewidths=.10, annot=False, mask=mask, fmt='.2g', cmap=\"PiYG\");\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot attribute charts\n",
    "\n",
    "def plot_attribute_chart(df, attribute):\n",
    "\n",
    "    # create chart\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(12, 6))\n",
    "    grid = gridspec.GridSpec(ncols=3, nrows=3, figure=fig)\n",
    "\n",
    "    # histogram\n",
    "    ax1 = fig.add_subplot(grid[0, :2])\n",
    "    sns.distplot(df.loc[:, attribute], norm_hist=True, ax=ax1)\n",
    "\n",
    "    # qq plot\n",
    "    ax2 = fig.add_subplot(grid[1, :2])\n",
    "    stats.probplot(df.loc[:, attribute], plot=ax2)\n",
    "\n",
    "    # boxplot\n",
    "    ax3 = fig.add_subplot(grid[0:3, 2])\n",
    "    sns.boxplot(df.loc[:, attribute], orient='v', ax=ax3)\n",
    "\n",
    "    #https://matplotlib.org/mpl-probscale/tutorial/closer_look_at_viz.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot attribute charts - multiple\n",
    "\n",
    "def plot_attributes_chart(df, attributes):\n",
    "\n",
    "    for attribute in attributes:\n",
    "        plot_attribute_chart(df, attribute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df meta data, order by correlation to target\n",
    "\n",
    "def get_df_meta_by_correlation(df_corr, df_meta, target):\n",
    "    \n",
    "    column_name = target + '_Corr'\n",
    "    \n",
    "    df_temp = df_corr.copy(deep=True)\n",
    "    \n",
    "    df_temp = df_temp[[target]].rename(\n",
    "        columns={target: column_name})\n",
    "\n",
    "    result = pd.merge(df_temp, \n",
    "        df_meta, \n",
    "        left_index=True, \n",
    "        right_index=True, \n",
    "        how='inner').sort_values(by=column_name, ascending=False)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_df_meta_by_correlation2(df_corr, df_meta, target):\n",
    "    \n",
    "    column_name = target + '_Corr'\n",
    "    column_name_abs = target + '_Corr_Abs'\n",
    "    \n",
    "    df_temp = df_corr.copy(deep=True)\n",
    "        \n",
    "    df_temp = df_temp[[target]].rename(\n",
    "        columns={target: column_name})\n",
    "\n",
    "    df_temp[column_name_abs] = df_temp[column_name].abs()    \n",
    "    \n",
    "    result = pd.merge(df_temp, \n",
    "        df_meta, \n",
    "        left_index=True, \n",
    "        right_index=True, \n",
    "        how='inner').sort_values(by=column_name_abs, ascending=False)\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing data\n",
    "\n",
    "def set_missing_data_with_freq_value(df, attribute):\n",
    "    \n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    imputer.fit(df[[attribute]])\n",
    "    \n",
    "    df[attribute] = imputer.transform(df[[attribute]])\n",
    "\n",
    "def set_missing_data_with_value(df, attribute, fill_value):\n",
    "    \n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=fill_value)\n",
    "    imputer.fit(df[[attribute]])\n",
    "    \n",
    "    df[attribute] = imputer.transform(df[[attribute]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attribute_categorical(df, target, attribute):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "    sns.catplot(x=attribute, y=target, kind='bar', data=df_raw_train.fillna('MISSING!!'), ax=ax[0])\n",
    "    sns.countplot(df_raw_train[attribute].fillna('MISSING!!'), ax=ax[1])\n",
    "    plt.close(2)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Data engineering\n",
    " -----\n",
    " 1. Load data\n",
    " 2. Briefly check both train and test dataset\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data path and file names\n",
    "file_path = \"/kaggle/input/house-prices-advanced-regression-techniques/\"\n",
    "file_path = \"\"\n",
    "file_name_train = \"train.csv\"\n",
    "file_name_test = \"test.csv\"\n",
    "file_name_meta = \"data_description.txt\"\n",
    "file_name_submission = \"sample_submission.csv\"\n",
    "file_separator = \",\"\n",
    "\n",
    "# these are numeric data types\n",
    "dtype_numeric = ['int64', 'uint8', 'float64']\n",
    "\n",
    "# total number of rows to show\n",
    "config_df_row_count = 8\n",
    "config_df_row_correlation_count = 20\n",
    "\n",
    "# target variable\n",
    "target = ['SalePrice']\n",
    "\n",
    "# variable - ignored list\n",
    "variable_ignored = ['Id']\n",
    "\n",
    "# variable - year month list\n",
    "variable_year_month = ['YearBuilt', 'YearRemodAdd', 'YrSold', 'MoSold']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "df_raw_train = pd.read_csv(\n",
    "    file_path+file_name_train, \n",
    "    sep=file_separator)\n",
    "\n",
    "df_raw_test = pd.read_csv(\n",
    "    file_path+file_name_test, \n",
    "    sep=file_separator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data - as it is\n",
    " ---\n",
    "\n",
    " 1. The dataset contains 1460 training set and 1459 test set.\n",
    " 2. The training set has the sale price while the test set does not.\n",
    " 3. There are 33 numeric attributes and 46 categorical attributes (23 nominal, 23 ordinal)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for data's shape\n",
    "file_names = [file_name_train, file_name_test]\n",
    "row_counts = [df_raw_train.shape[0], df_raw_test.shape[0]]\n",
    "col_counts = [df_raw_train.shape[1], df_raw_test.shape[1]]\n",
    "list_of_tuples = list(zip(file_names, row_counts, col_counts))  \n",
    "    \n",
    "pd.DataFrame(list_of_tuples, columns = ['file_name', 'row_counts', 'col_counts'])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample train data\n",
    "df_raw_train.sample(config_df_row_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample test data\n",
    "df_raw_test.head(config_df_row_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train data metadata\n",
    "df_raw_train_meta = get_dataframe_metadata(df_raw_train)\n",
    "df_raw_train_meta.head(config_df_row_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test data metadata\n",
    "df_raw_test_meta = get_dataframe_metadata(df_raw_test)\n",
    "df_raw_test_meta.head(config_df_row_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### SalePrice\n",
    " ---\n",
    " 1. SalePrice is the target variable\n",
    " 2. Not normally distributed (skew: 1.88, kurtosis: 6.54)\n",
    " 3. Has some outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = 'SalePrice'\n",
    "plot_attribute_chart(df_raw_train, attribute)\n",
    "df_raw_train_meta.loc[df_raw_train_meta.index == attribute, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Exterior\n",
    " ---\n",
    "\n",
    " 1. **ExterCond**, evaluates the present condition of the material on the exterior (**Ex**: Excellent, **Gd**: Good, **TA**: Average/Typical, **Fa**: Fair, **Po**:\tPoor)\n",
    "\n",
    " 2. **ExterQual**, evaluates the quality of the material on the exterior\n",
    "\n",
    " 3. **Exterior1st** , **Exterior2nd**: Exterior covering on house\n",
    "\n",
    " 4. **Fence quality** (**GdPrv**: Good Privacy, **MnPrv**: Minimum Privacy, **GdWo**: Good Wood, **MnWw**: Minimum Wood/Wire, **NA**: No Fence)\n",
    "\n",
    " 5. **RoofMatl**: Roof material (**ClyTile**: Clay or Tile, **CompShg**: Standard (Composite) Shingle, **Membran**: Membrane, **Metal**: Metal, **Roll**: Roll, **Tar&Grv**: Gravel & Tar, **WdShake**: Wood Shakes, **WdShngl**: Wood Shingles)\n",
    "\n",
    " 6. **RoofStyle**: Type of roof (**Flat**: Flat, **Gable**: Gable, **Gambrel**: Gabrel (Barn), **Hip**: Hip, **Mansard**: Mansard, **Shed**: Shed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'ExterCond')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'ExterQual')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'Exterior1st')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'Exterior2nd')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'Fence')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'RoofMatl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'RoofStyle')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Garage\n",
    " ---\n",
    "\n",
    " 1. **GarageArea**, size of garage in square feet\n",
    " 2. **GarageCars**, size of garage in car capacity\n",
    " 3. **GarageQual**, garage quality\n",
    " 4. **GarageCond**, garage condition\n",
    " 5. **GarageFinish**, interior finish of the garage\n",
    " 6. **GarageType**, garage location\n",
    " 7. **GarageYrBlt**, year garage was built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"GarageArea\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'GarageCars')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'GarageQual')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'GarageCond')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'GarageFinish')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'GarageType')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'GarageYrBlt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Basement\n",
    " ---\n",
    " 1. **TotalBsmtSF**, total square feet of basement area\n",
    " 2. **BsmtQual**, evaluates the height of the basement\n",
    " 3. **BsmtCond**, evaluates the general condition of the basement\n",
    " 4. **BsmtExposure**, refers to walkout or garden level walls\n",
    " 5. **BsmtFinType1** , **BsmtFinType1**, rating of basement finished area\n",
    " 6. **BsmtFinSF1**, type 1 finished square feet\n",
    " 7. **BsmtFinSF2**, type 2 finished square feet\n",
    " 7. **BsmtUnfSF**, Unfinished square feet of basement area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"TotalBsmtSF\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'BsmtQual')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'BsmtCond')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'BsmtExposure')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'BsmtFinType1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'BsmtFinType2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"BsmtFinSF1\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"BsmtFinSF2\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"BsmtUnfSF\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Kitchen\n",
    " ---\n",
    " 1. **Kitchen**, kitchens above grade\n",
    " 2. **KitchenQual**, kitchen quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'KitchenAbvGr')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'KitchenQual')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Living area\n",
    " ---\n",
    " 1. **Fireplaces**, number of fireplaces\n",
    " 2. **FireplaceQu**, fireplace quality\n",
    " 3. **GrLivArea**, Above grade (ground) living area square feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'Fireplaces')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'FireplaceQu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"GrLivArea\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Bedrooms and bathrooms\n",
    " ---\n",
    " 1. **BedroomAbvGr**, bedrooms above grade (does NOT include basement bedrooms)\n",
    " 2. **TotRmsAbvGrd**, total rooms above grade (does not include bathrooms)\n",
    " 3. **FullBath**, full bathrooms above grade\n",
    " 4. **HalfBath**, half baths above grade\n",
    " 5. **BsmtFullBath**, basement full bathrooms\n",
    " 6. **BsmtHalfBath**, basement half bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'BedroomAbvGr')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'TotRmsAbvGrd')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'FullBath')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'HalfBath')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'BsmtFullBath')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'BsmtHalfBath')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Facilities\n",
    " ---\n",
    " 1. **PoolArea**, pool area in square feet\n",
    " 2. **PoolQC**, pool quality\n",
    " 3. **MiscFeature**: Miscellaneous feature not covered in other categories\n",
    " 4. **MiscVal**: $Value of miscellaneous feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'PoolQC')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'PoolArea')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'MiscFeature')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"MiscVal\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Utilities\n",
    " ---\n",
    " 1. **Electrical**: Electrical system\n",
    " 2. **CentralAir**: Central air conditioning\n",
    " 3. **Heating**: Type of heating\n",
    " 4. **HeatingQC**: Heating quality and condition\n",
    " 5. **Utilities**: Type of utilities available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'Electrical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'CentralAir')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'Heating')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'HeatingQC')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'Utilities')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Building - general\n",
    " ---\n",
    " 1. **OverallQual**, rates the overall material and finish of the house\n",
    " 2. **OverallCond**, rates the overall condition of the house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'OverallQual')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'OverallCond')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Building\n",
    " ---\n",
    " 1. **BldgType**, type of dwelling\n",
    " 2. **HouseStyle**, style of dwelling\n",
    " 3. **Foundation**, type of foundation\n",
    " 4. **Functional**, home functionality (Assume typical unless deductions are warranted)\n",
    " 5. **MasVnrArea**, masonry veneer area in square feet\n",
    " 6. **MasVnrType**, masonry veneer type\n",
    " 7. **1stFlrSF**, first floor square feet\n",
    " 8. **2ndFlrSF**, second floor square feet\n",
    " 9. **LowQualFinSF**, low quality finished square feet (all floors)\n",
    " 10. **WoodDeckSF**, wood deck area in square feet\n",
    " 11. **OpenPorchSF**, open porch area in square feet\n",
    " 12. **EnclosedPorch**, enclosed porch area in square feet\n",
    " 13. **3SsnPorch**, three season porch area in square feet\n",
    " 14. **ScreenPorch**, screen porch area in square feet\n",
    " 15. **YearBuilt**, original construction date\n",
    " 16. **YearRemodAdd**, remodel date (same as construction date if no remodeling or additions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'BldgType')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'HouseStyle')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'Foundation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'Functional')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"MasVnrArea\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'MasVnrType')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"1stFlrSF\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"2ndFlrSF\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"LowQualFinSF\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"WoodDeckSF\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"OpenPorchSF\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"EnclosedPorch\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"3SsnPorch\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"ScreenPorch\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"YearBuilt\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"YearRemodAdd\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Lot\n",
    " ---\n",
    " 1. **LotArea**, lot size in square feet\n",
    " 2. **LotFrontage**, linear feet of street connected to property\n",
    " 3. **LotShape**, general shape of property\n",
    " 4. **LotConfig**, lot configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"LotArea\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"LotFrontage\", y=\"SalePrice\", data=df_raw_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'LotShape')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'LotConfig')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Surroundings\n",
    "\n",
    " 1. **Alley**, type of alley access to property\n",
    " 2. **PavedDrive**, paved driveway\n",
    " 3. **Street**, type of road access to property\n",
    " 4. **LandContour**, flatness of the property\n",
    " 5. **LandSlope**, slope of property\n",
    " 6. **Condition1**, proximity to various conditions\n",
    " 7. **Condition2**, proximity to various conditions (if more than one is present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'Alley')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'PavedDrive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'Street')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'LandContour')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'LandSlope')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'Condition1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'Condition2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Area\n",
    " ---\n",
    " 1. **MSZoning**, identifies the general zoning classification of the sale.\n",
    " 2. **Neighborhood**, physical locations within Ames city limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'MSZoning')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'Neighborhood')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Sell condition\n",
    " ---\n",
    " 1. **SaleType**, type of sale\n",
    " 2. **SaleCondition**, condition of sale\n",
    " 3. **YrSold**, year sold (YYYY)\n",
    " 4. **MoSold**, month sold (MM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'SaleType')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'SaleCondition')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'YrSold')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attribute_categorical(df_raw_train, target[0], 'MoSold')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.ExcelWriter('output.xlsx') as writer:\n",
    "#    df_raw_train.to_excel(writer, sheet_name='train')\n",
    "#    df_raw_train_meta.to_excel(writer, sheet_name='train_meta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data as it is - numeric correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get numeric attributes\n",
    "numeric_attributes = df_raw_train_meta[np.in1d(df_raw_train_meta.dtype, dtype_numeric)].index\n",
    "numeric_attributes = list(set(numeric_attributes) - set(variable_ignored) - set(variable_year_month) - set(target))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute correlation matrix\n",
    "df_raw_train_corr_matrix = compute_correlation_matrix(\n",
    "    df_raw_train, \n",
    "    target,\n",
    "    numeric_attributes)\n",
    "\n",
    "# plot correlations\n",
    "plot_correlation_matrix(\n",
    "    df_raw_train_corr_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get attribute's description, order by correlation\n",
    "df_raw_train_meta_sorted = get_df_meta_by_correlation2(\n",
    "    df_raw_train_corr_matrix, \n",
    "    df_raw_train_meta,\n",
    "    target[0])\n",
    "\n",
    "df_raw_train_meta_sorted.head(\n",
    "    config_df_row_correlation_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot target to features 1-d pca\n",
    "plot_pca_smarter(df_raw_train, \n",
    "    df_raw_train_meta_sorted, \n",
    "    target, \n",
    "    14)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://seaborn.pydata.org/tutorial/regression.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data - baseline cleaning\n",
    " ---\n",
    "\n",
    " Based on the **data as it is** inspection,\n",
    "\n",
    " 1. Derive atrribute from other attribute(s)\n",
    "     * YrMoSold --> YrSold + MoSold --> Yr*100 + Mo (X)\n",
    "     * Age --> (YrSold + MoSold) - YearBuilt\n",
    "\n",
    " 2. Categorical attributes - one hot encoding\n",
    "     * BldgType: Type of dwelling\n",
    "     * HouseStyle: Style of dwelling\n",
    "\n",
    " 3. Categorical attributes - specified order numeric encoding\n",
    "     * LotShape\n",
    "     * Street - Type of road access to property\n",
    "     * Alley - Type of alley access to property\n",
    "     * LandSlope - Slope of property\n",
    "     * HeatingQC - Heating quality and condition\n",
    "     * CentralAir - Central air conditioning\n",
    "     * KitchenQual - Kitchen quality\n",
    "     * GarageCond - Garage condition\n",
    "     * PoolQC -  Pool quality\n",
    "\n",
    " 4.  Missing data handling\n",
    "     * MasVnrArea (Masonry veneer area in square feet) --> if Null set to 0\n",
    "     * LotFrontage (Linear feet of street connected to property) --> set to most frequent value\n",
    "     * GarageYrBlt --> set to YearBuilt if Null\n",
    "\n",
    " 5. Subjectively remove columns that represent similar attribute\n",
    "     * Id (not relevant)\n",
    "     * GarageArea (highly correlated with GarageCars)\n",
    "     * GarageYrBlt (highly correlated with YearBuilt and YearRemodAdd)\n",
    "     * TotRmsAbvGrd (highly correlated with GrLivArea)\n",
    "     * BsmtFinSF1 and BsmtFinSF2 (equivalent to TotalBsmtSF)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone previous df to this section df\n",
    "df_base_train = df_raw_train.copy(deep=True)\n",
    "df_base_test = df_raw_test.copy(deep=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handler for missing data\n",
    "\n",
    "def data_missing_handler(df):\n",
    "\n",
    "    # set MasVnrArea 0 if its null\n",
    "    set_missing_data_with_value(df, 'MasVnrArea', 0)\n",
    "\n",
    "    # set MasVnrArea 0 if its null\n",
    "    set_missing_data_with_value(df, 'GarageCars', 0)    \n",
    "\n",
    "    # set MasVnrArea 0 if its null\n",
    "    set_missing_data_with_value(df, 'FullBath', 1)\n",
    "    set_missing_data_with_value(df, 'BsmtFullBath', 1)\n",
    "    set_missing_data_with_value(df, 'HalfBath', 1)\n",
    "    set_missing_data_with_value(df, 'BsmtHalfBath', 1)\n",
    "    \n",
    "    # set MasVnrArea 0 if its null\n",
    "    set_missing_data_with_value(df, 'BsmtUnfSF', 0) \n",
    "    \n",
    "    # set MasVnrArea 0 if its null\n",
    "    set_missing_data_with_value(df, 'TotalBsmtSF', 0)\n",
    "    set_missing_data_with_value(df, '1stFlrSF', 0)\n",
    "    set_missing_data_with_value(df, '2ndFlrSF', 0)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # set LotFrontage to most frequent value if its null\n",
    "    set_missing_data_with_freq_value(df, 'LotFrontage')\n",
    "    \n",
    "    # set TotalBsmtSF to most frequent value if its null\n",
    "    set_missing_data_with_freq_value(df, 'TotalBsmtSF')\n",
    "   \n",
    "    # set GarageYrBlt to YearBuilt if its null\n",
    "    df.loc[df['GarageYrBlt'].isnull(), ['GarageYrBlt']] = df['YearBuilt']\n",
    "\n",
    "data_missing_handler(df_base_train)\n",
    "data_missing_handler(df_base_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Derives attribute(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_derive_attributes(df):\n",
    "    \n",
    "    # age of the house\n",
    "    df['d_HouseAge'] = (df['YrSold'] + (df['MoSold'] / 12)) - df['YearBuilt']\n",
    "\n",
    "    # number of years since last renovation\n",
    "    df['d_RemodAge'] = (df['YrSold'] + (df['MoSold'] / 12)) - df['YearRemodAdd']\n",
    "\n",
    "    # just take the age as renovation age\n",
    "    df['d_Age'] = df['d_RemodAge']\n",
    "        \n",
    "    df['d_HasFireplace'] = df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)    \n",
    "    df['d_HasPool'] = df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    df['d_Bath'] = df['FullBath'] + df['BsmtFullBath'] + (0.5 * df['HalfBath']) + (0.5 * df['BsmtHalfBath'])\n",
    "    df['d_TotalPorchSF'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch'] + df['WoodDeckSF'] \n",
    "    # total floor sqf\n",
    "\n",
    "    df['d_HasGarage'] = df['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    \n",
    "    df['d_HasBsmt'] = df['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    df['d_Has2ndFlr'] = df['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    df['d_TotalFlrSF'] = df['1stFlrSF'] + df['2ndFlrSF']\n",
    "    df['d_TotalBldgSF'] = df['1stFlrSF'] + df['2ndFlrSF'] + df['TotalBsmtSF']\n",
    "    df['d_GardenSF'] = df['LotArea'] - df['1stFlrSF']\n",
    "    \n",
    "data_derive_attributes(df_base_train) \n",
    "data_derive_attributes(df_base_test) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive Neighborhood's code value based on the price per square feet\n",
    "\n",
    "def data_derive_neighborhood_code(df):\n",
    "    \n",
    "    # get new dataframe for temp processing\n",
    "    df_temp = df_base_train[['Neighborhood', 'SalePrice', 'd_TotalFlrSF']].copy(deep=True)\n",
    "\n",
    "    # compute psf, price per sequare feet\n",
    "    df_temp['d_PricePerSF'] = df_base_train['SalePrice'] / df_base_train['d_TotalFlrSF']\n",
    "\n",
    "    # compute psf for each Neighborhood\n",
    "    df_temp_group = df_temp.groupby(['Neighborhood'], as_index=False).agg({\"d_PricePerSF\": [np.mean, np.median]})\n",
    "    df_temp_group.columns = ['_'.join(t).rstrip('_') for t in df_temp_group.columns]\n",
    "\n",
    "    # sort dataframe on psf asncending order\n",
    "    df_temp_group.sort_values(by=\"d_PricePerSF_median\", ascending=True, inplace=True)\n",
    "\n",
    "    # set computed Neighborhood's code value\n",
    "    df_temp_group['d_Neighborhood_Code'] = df_temp_group.reset_index().index + 1\n",
    "    \n",
    "    return df_temp_group\n",
    "\n",
    "\n",
    "df_neighborhood_code = data_derive_neighborhood_code(df_base_train)\n",
    "\n",
    "df_base_train = pd.merge(df_base_train, \n",
    "    df_neighborhood_code[['Neighborhood', 'd_Neighborhood_Code']], \n",
    "    how='inner', \n",
    "    left_on='Neighborhood', \n",
    "    right_on='Neighborhood') \n",
    "\n",
    "df_base_test = pd.merge(df_base_test, \n",
    "    df_neighborhood_code[['Neighborhood', 'd_Neighborhood_Code']], \n",
    "    how='inner', \n",
    "    left_on='Neighborhood', \n",
    "    right_on='Neighborhood') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_onehot_encoding(df):\n",
    "    \n",
    "    \n",
    "    # one hot encoding - MSZoning\n",
    "    #df = pd.concat([df, \n",
    "    #pd.get_dummies(df['MSZoning'], prefix='MSZoning')], axis=1) \n",
    "    \n",
    "    # one hot encoding - BldgType\n",
    "    #df = pd.concat([df, \n",
    "    #pd.get_dummies(df['BldgType'], prefix='BldgType')], axis=1)\n",
    "\n",
    "    # one hot encoding - HouseStyle\n",
    "    #df = pd.concat([df, \n",
    "    #pd.get_dummies(df['HouseStyle'], prefix='HouseStyle')], axis=1) \n",
    "    \n",
    "    return df\n",
    "\n",
    "df_base_train = data_onehot_encoding(df_base_train)\n",
    "df_base_test = data_onehot_encoding(df_base_test)\n",
    "\n",
    "df_base_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Numeric encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_numeric_encoding(df):\n",
    "\n",
    "    # numeric encoding - GarageQual\n",
    "    df['BsmtQual_Encoded'] = df['BsmtQual'].map( \n",
    "        {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, np.NaN:2})\n",
    "    \n",
    "    # numeric encoding - BsmtCond\n",
    "    ##df['BsmtCond_Encoded'] = df['BsmtCond'].map( \n",
    "    ##    {'Ex':5, 'Gd':4, 'TA':3, 'Fa':2, 'Po':1, np.NaN:2})    \n",
    "    \n",
    "    # numeric encoding - BsmtExposure\n",
    "    df['BsmtExposure_Encoded'] = df['BsmtExposure'].map( \n",
    "        {'Ex':5, 'Gd':4, 'Av':3, 'Mn':2, 'No':1, np.NaN:1})         \n",
    "    \n",
    "    # numeric encoding - ExterQual\n",
    "    df['ExterQual_Encoded'] = df['ExterQual'].map( \n",
    "        {'Ex':4, 'Gd':3, 'TA':2, 'Fa':1, 'Po':1})\n",
    "\n",
    "    # numeric encoding - ExterCond\n",
    "    df['ExterCond_Encoded'] = df['ExterCond'].map( \n",
    "        {'Ex':4, 'Gd':3, 'TA':3, 'Fa':2, 'Po':1})\n",
    "       \n",
    "    # numeric encoding - CentralAir\n",
    "    df['CentralAir_Encoded'] = df['CentralAir'].map( \n",
    "        {'Y':2, 'N':1})   \n",
    "    \n",
    "    # numeric encoding - CentralAir\n",
    "    df['Electrical_Encoded'] = df['Electrical'].map( \n",
    "        {'SBrkr':3, 'FuseA':2, 'FuseF':2, 'FuseP':2, 'Mix':1, np.NaN:3})       \n",
    "    \n",
    "    # numeric encoding - KitchenQual\n",
    "    df['KitchenQual_Encoded'] = df['KitchenQual'].map( \n",
    "        {'Ex':4, 'Gd':3, 'TA':2, 'Fa':1, 'Po':1})   \n",
    "    \n",
    "    # numeric encoding - HeatingQC\n",
    "    df['HeatingQC_Encoded'] = df['HeatingQC'].map( \n",
    "        {'Ex':4, 'Gd':3, 'TA':2, 'Fa':1, 'Po':1})   \n",
    "    \n",
    "    # numeric encoding - Alley\n",
    "    df['Alley_Encoded'] = df['Alley'].map( \n",
    "        {'Pave':2, 'Grvl':1})    \n",
    "\n",
    "    # numeric encoding - PoolQC\n",
    "    #df['PoolQC_Encoded'] = df['PoolQC'].map( \n",
    "    #    {'Ex':4, 'Gd':3, 'Fa':2, np.NaN:1})   \n",
    "    \n",
    "    # numeric encoding - LotShape\n",
    "    df['LotShape_Encoded'] = df['LotShape'].map( \n",
    "        {'Reg':2, 'IR1':1, 'IR2':1, 'IR3':1})\n",
    "\n",
    "    # numeric encoding - LandSlope - XXX\n",
    "    df['LandSlope_Encoded'] = df['LandSlope'].map( \n",
    "        {'Gtl':3, 'Mod':2, 'Sev':1})\n",
    "\n",
    "    # numeric encoding - GarageFinish\n",
    "    df['GarageFinish_Encoded'] = df['GarageFinish'].map( \n",
    "        {'Fin':3, 'RFn':2, 'Unf':1, np.NaN: 0})    \n",
    "    \n",
    "    # numeric encoding - GarageQual\n",
    "    df['GarageQual_Encoded'] = df['GarageQual'].map( \n",
    "        {'Ex':3, 'Gd':3, 'TA':2, 'Fa':1, 'Po':1, np.NaN: 0})\n",
    "    \n",
    "    # numeric encoding - GarageQual\n",
    "    df['GarageType_Encoded'] = df['GarageType'].map( \n",
    "        {'BuiltIn':4, 'Attchd':3, 'Basment':2, '2Types':2, 'Detchd': 1, 'CarPort':1, np.NaN: 0})    \n",
    "    \n",
    "    # numeric encoding - GarageCond XXX\n",
    "    ##df['GarageCond_Encoded'] = df['GarageCond'].map( \n",
    "    ##    {'Ex':4, 'Gd':3, 'TA':2, 'Fa':1, 'Po':1, 'NA':np.NaN})\n",
    "    \n",
    "    # numeric encoding - Foundation\n",
    "    df['Foundation_Encoded'] = df['Foundation'].map( \n",
    "        {'PConc':6, 'CBlock':5, 'BrkTil':4, 'Stone':3, 'Wood': 3,  'Slab':3 })\n",
    "    \n",
    "    # numeric encoding - Foundation\n",
    "    df['MasVnrType_Encoded'] = df['MasVnrType'].map( \n",
    "        {'Stone':4, 'BrkFace':3, 'None':2, 'BrkCmn':1, np.NaN: 1 })\n",
    "\n",
    "    # numeric encoding - Paved drive\n",
    "    df['PavedDrive_Encoded'] = df['PavedDrive'].map( \n",
    "        {'Y':4, 'N':0, 'P':0, np.NaN: 1 }) \n",
    "    \n",
    "    # numeric encoding - MSZoning\n",
    "    df['MSZoning_Encoded'] = df['MSZoning'].map( \n",
    "        {'FV':3, 'RL':3, 'RH':2, 'RM': 2, 'c(all)': 1, np.NaN: 1 })     \n",
    "    \n",
    "    # numeric encoding - OverallQual\n",
    "    #df['OverallQual_Encoded'] = df['OverallQual'].map( \n",
    "    #    {'0':4, '1':4, '2':4, '3':4, '4':4, '5':5, '6':6, '7':7, '8':8, '9':8, '10':8 })      \n",
    "\n",
    "data_numeric_encoding(df_base_train)\n",
    "data_numeric_encoding(df_base_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_base_train['GarageArea'].unique()\n",
    "df_base_train.loc[df_base_train['GarageArea'] == 0].shape\n",
    "df_base_train.loc[df_base_train['GarageFinish'].isnull()].shape\n",
    "df_base_train.loc[df_base_train['GarageFinish_Encoded'] == 0].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " #### Numeric encoding - missing data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handler for missing encoded data\n",
    "    \n",
    "def data_numeric_encoding_missing(df):\n",
    "    \n",
    "    # impute missing encoded data - LotShape_Econded\n",
    "    set_missing_data_with_freq_value(df, 'GarageFinish_Encoded')    \n",
    "    \n",
    "    # impute missing encoded data - LotShape_Econded\n",
    "    set_missing_data_with_freq_value(df, 'LotShape_Encoded')\n",
    "\n",
    "    # impute missing encoded data - Alley_Encoded\n",
    "    set_missing_data_with_freq_value(df, 'Alley_Encoded')\n",
    "\n",
    "    # impute missing encoded data - LandSlope_Encoded xxx\n",
    "    set_missing_data_with_freq_value(df, 'LandSlope_Encoded')\n",
    "\n",
    "    # impute missing encoded data - CentralAir_Encoded\n",
    "    set_missing_data_with_freq_value(df, 'CentralAir_Encoded')\n",
    "\n",
    "    # impute missing encoded data - HeatingQC_Encoded\n",
    "    set_missing_data_with_freq_value(df, 'HeatingQC_Encoded')\n",
    "\n",
    "    # impute missing encoded data - KitchenQual_Encoded\n",
    "    set_missing_data_with_freq_value(df, 'KitchenQual_Encoded')\n",
    "\n",
    "    # impute missing encoded data - GarageQual_Encoded\n",
    "    set_missing_data_with_freq_value(df, 'GarageQual_Encoded')\n",
    "\n",
    "    # impute missing encoded data - GarageCond_Encoded - XXX\n",
    "    ##set_missing_data_with_freq_value(df, 'GarageCond_Encoded')\n",
    "    \n",
    "    # impute missing encoded data - Foundation_Encoded\n",
    "    set_missing_data_with_value(df, 'GarageType_Encoded', 0)       \n",
    "    \n",
    "    # impute missing encoded data - BsmtQual_Encoded\n",
    "    set_missing_data_with_freq_value(df, 'BsmtQual_Encoded')\n",
    "\n",
    "    # impute missing encoded data - GarageCond_Encoded\n",
    "    ##set_missing_data_with_freq_value(df, 'BsmtCond_Encoded')\n",
    "\n",
    "    # impute missing encoded data - BsmtExposure_Encoded\n",
    "    set_missing_data_with_freq_value(df, 'BsmtExposure_Encoded')\n",
    "    \n",
    "    # impute missing encoded data - PoolQC_Encoded\n",
    "    #set_missing_data_with_freq_value(df, 'PoolQC_Encoded')\n",
    "        \n",
    "    # impute missing encoded data - ExterQual_Encoded\n",
    "    set_missing_data_with_freq_value(df, 'ExterQual_Encoded')\n",
    "\n",
    "    # impute missing encoded data - ExterCond_Encoded\n",
    "    set_missing_data_with_freq_value(df, 'ExterCond_Encoded')\n",
    "        \n",
    "    # impute missing encoded data - Foundation_Encoded\n",
    "    set_missing_data_with_freq_value(df, 'Foundation_Encoded')        \n",
    "\n",
    "    # impute missing encoded data - MSZoning\n",
    "    set_missing_data_with_freq_value(df, 'MSZoning_Encoded')   \n",
    "\n",
    "\n",
    "    \n",
    "data_numeric_encoding_missing(df_base_train)\n",
    "data_numeric_encoding_missing(df_base_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Other - missing data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handler for missing data\n",
    "\n",
    "def data_missing_handler(df):\n",
    "\n",
    "    # set MasVnrArea 0 if its null\n",
    "    set_missing_data_with_value(df, 'MasVnrArea', 0)\n",
    "\n",
    "    # set MasVnrArea 0 if its null\n",
    "    set_missing_data_with_value(df, 'GarageCars', 0)    \n",
    "\n",
    "    # set MasVnrArea 0 if its null\n",
    "    set_missing_data_with_value(df, 'd_Bath', 1)\n",
    "    \n",
    "    \n",
    "    # set MasVnrArea 0 if its null\n",
    "    set_missing_data_with_value(df, 'BsmtUnfSF', 0)    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # set LotFrontage to most frequent value if its null\n",
    "    set_missing_data_with_freq_value(df, 'LotFrontage')\n",
    "    \n",
    "    # set TotalBsmtSF to most frequent value if its null\n",
    "    set_missing_data_with_freq_value(df, 'TotalBsmtSF')\n",
    "   \n",
    "    # set GarageYrBlt to YearBuilt if its null\n",
    "    df.loc[df['GarageYrBlt'].isnull(), ['GarageYrBlt']] = df['YearBuilt']\n",
    "    \n",
    "    \n",
    "\n",
    "#data_missing_handler(df_base_train)\n",
    "#data_missing_handler(df_base_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude un-used columns\n",
    "\n",
    "exclusions = [#'Id', \n",
    "    'd_HouseAge', 'd_RemodAge',\n",
    "    'YrSold', 'MoSold', 'YearBuilt', 'YearRemodAdd', \n",
    "    'GarageArea', 'GarageYrBlt',\n",
    "\n",
    "    'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'WoodDeckSF',\n",
    "    \n",
    "    'Fireplaces', 'PoolArea', 'PoolQC',\n",
    "    'FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath', \n",
    "    'BsmtFinSF1', 'BsmtFinSF2',   \n",
    "    '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
    "\n",
    "    'MiscFeature', 'MiscVal', \n",
    "    \n",
    "    'TotRmsAbvGrd', 'GrLivArea'\n",
    "] \n",
    "\n",
    "df_base_train = df_base_train.drop(exclusions, axis=1, errors='ignore')\n",
    "df_base_test = df_base_test.drop(exclusions, axis=1, errors='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe's metadata\n",
    "df_base_train_meta = get_dataframe_metadata(df_base_train)\n",
    "\n",
    "df_base_train_meta.head(config_df_row_correlation_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_attributes = df_base_train_meta[np.in1d(df_base_train_meta.dtype, dtype_numeric)].index\n",
    "numeric_attributes = list(set(numeric_attributes) - set(variable_ignored) - set(variable_year_month) - set(target))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation matrix\n",
    "df_base_train_corr_matrix = compute_correlation_matrix(df_base_train, target, numeric_attributes)\n",
    "\n",
    "# plot correlations\n",
    "plot_correlation_matrix(df_base_train_corr_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get attribute's description, order by correlation\n",
    "df_base_train_meta_sorted = get_df_meta_by_correlation2(\n",
    "    df_base_train_corr_matrix, \n",
    "    df_base_train_meta,\n",
    "    target[0])\n",
    "\n",
    "df_base_train_meta_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot target to features 1-d pca\n",
    "plot_pca_smarter(df_base_train, df_base_train_meta_sorted, target, 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Data - outliers cleaning\n",
    " ---\n",
    "\n",
    " Use extreme value analysis\n",
    "\n",
    " Assume a Gaussian distribution and remove 3 standard deviations from the mean, for these numeric non categorical attributes\n",
    "\n",
    " * GrLivArea\n",
    " * 1stFlrSF\n",
    " * BsmtFinSF1\n",
    " * LotArea\n",
    " * BsmtUnfSF\n",
    "\n",
    " [How to identify outliers](https://machinelearningmastery.com/how-to-identify-outliers-in-your-data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_outlier_train = df_base_train.copy(deep=True)\n",
    "df_clean_outlier_train_meta = df_base_train_meta.copy(deep=True)\n",
    "\n",
    "df_clean_outlier_test = df_base_test.copy(deep=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_attributes = df_clean_outlier_train_meta[np.in1d(df_clean_outlier_train_meta.dtype, dtype_numeric)].index\n",
    "numeric_attributes = list(set(numeric_attributes) - set(variable_ignored) - set(variable_year_month) - set(target))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['SalePrice', 'LotArea', 'd_TotalFlrSF', 'TotalBsmtSF'] \n",
    "\n",
    "for attribute in attributes:\t\n",
    "\n",
    "    upper_value = float(df_clean_outlier_train_meta.loc[df_clean_outlier_train_meta.index == attribute]['upper_3s_3'])\t\n",
    "    lower_value = float(df_clean_outlier_train_meta.loc[df_clean_outlier_train_meta.index == attribute]['lower_3s_3'])\t\n",
    "    \n",
    "    df_clean_outlier_train.loc[(df_clean_outlier_train[attribute] > upper_value) | (df_clean_outlier_train[attribute] < lower_value), 'Outliers'] = attribute\t\n",
    "                          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_outlier_train = df_clean_outlier_train.loc[df_clean_outlier_train['Outliers'].isna()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe's metadata\n",
    "df_clean_outlier_train_meta = get_dataframe_metadata(df_clean_outlier_train)\n",
    "\n",
    "df_clean_outlier_train_meta.head(config_df_row_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = 'SalePrice'\n",
    "\n",
    "plot_attribute_chart(df_base_train, attribute)\n",
    "plot_attribute_chart(df_clean_outlier_train, attribute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = 'd_TotalFlrSF'\n",
    "\n",
    "plot_attribute_chart(df_base_train, attribute)\n",
    "plot_attribute_chart(df_clean_outlier_train, attribute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = 'TotalBsmtSF'\n",
    "\n",
    "plot_attribute_chart(df_base_train, attribute)\n",
    "plot_attribute_chart(df_clean_outlier_train, attribute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = 'LotArea'\n",
    "\n",
    "plot_attribute_chart(df_base_train, attribute)\n",
    "plot_attribute_chart(df_clean_outlier_train, attribute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = 'MasVnrArea'\n",
    "\n",
    "plot_attribute_chart(df_base_train, attribute)\n",
    "plot_attribute_chart(df_clean_outlier_train, attribute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation matrix\n",
    "df_clean_outlier_train_corr_matrix = compute_correlation_matrix(df_clean_outlier_train, target, numeric_attributes)\n",
    "\n",
    "# plot correlations\n",
    "plot_correlation_matrix(df_clean_outlier_train_corr_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get attribute's description, order by correlation\n",
    "df_clean_outlier_train_meta_sorted = get_df_meta_by_correlation2(\n",
    "    df_clean_outlier_train_corr_matrix, \n",
    "    df_clean_outlier_train_meta,\n",
    "    target[0])\n",
    "\n",
    "df_clean_outlier_train_meta_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot target to features 1-d pca\n",
    "plot_pca_smarter(df_clean_outlier_train, \n",
    "    df_clean_outlier_train_meta_sorted, \n",
    "    target, \n",
    "    15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Data - normalising\n",
    " ---\n",
    "\n",
    " [scale-machine-learning-data](https://machinelearningmastery.com/scale-machine-learning-data-scratch-python/)\n",
    "\n",
    " [prepare-data-machine-learning](https://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_norm_train = df_clean_outlier_train.copy(deep=True)\n",
    "df_clean_norm_train_meta = df_clean_outlier_train_meta.copy(deep=True)\n",
    "\n",
    "df_clean_norm_test = df_clean_outlier_test.copy(deep=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_attributes = df_clean_norm_train_meta[np.in1d(df_clean_norm_train_meta.dtype, dtype_numeric)].index\n",
    "numeric_attributes = list(set(numeric_attributes) - set(variable_ignored) - set(variable_year_month) - set(target))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_norm_train_meta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_standardize(df, attribute_to_scale):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    scaler.fit(df[attribute_to_scale])\n",
    "\n",
    "    attributes_scaled = scaler.transform(df[attribute_to_scale])\n",
    "\n",
    "    #df[attribute_to_scale] = attributes_scaled\n",
    "\n",
    "\n",
    "data_standardize(df_clean_norm_train, numeric_attributes + target)\n",
    "data_standardize(df_clean_norm_test, numeric_attributes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attribute_to_scale = numeric_attributes + target\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "#scaler.fit(df_clean_norm_train[attribute_to_scale])\n",
    "\n",
    "#attributes_scaled = scaler.transform(df_clean_norm_train[attribute_to_scale])\n",
    "\n",
    "#df_clean_norm_train[attribute_to_scale] = attributes_scaled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.seterr(divide = 'ignore') \n",
    "\n",
    "#attribute_to_normalise = numeric_attributes + target\n",
    "\n",
    "#transformer = PowerTransformer()\n",
    "#transformer.fit(df_clean_norm_train[attribute_to_normalise])\n",
    "\n",
    "#df1 = pd.DataFrame(transformer.transform(df_clean_norm_train[attribute_to_normalise]), columns=attribute_to_normalise)\n",
    "\n",
    "#df_clean_norm_train = df_clean_norm_train.drop(attributes + target, axis=1)\n",
    "\n",
    "#df_clean_norm_train = pd.merge(df_clean_norm_train, df1, right_index=True, left_index=True)\n",
    "\n",
    "#df_clean_norm_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe's metadata\n",
    "df_clean_norm_train_meta = get_dataframe_metadata(df_clean_norm_train)\n",
    "\n",
    "df_clean_norm_train_meta.head(config_df_row_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = 'SalePrice'\n",
    "\n",
    "plot_attribute_chart(df_clean_outlier_train, attribute)\n",
    "plot_attribute_chart(df_clean_norm_train, attribute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attribute = 'GrLivArea'\n",
    "\n",
    "#plot_attribute_chart(df_clean_outlier_train, attribute)\n",
    "#plot_attribute_chart(df_clean_norm_train, attribute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = 'd_TotalFlrSF'\n",
    "\n",
    "plot_attribute_chart(df_clean_outlier_train, attribute)\n",
    "plot_attribute_chart(df_clean_norm_train, attribute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation matrix\n",
    "df_clean_norm_train_corr_matrix = compute_correlation_matrix(df_clean_norm_train, target, numeric_attributes)\n",
    "\n",
    "# plot correlations\n",
    "plot_correlation_matrix(df_clean_norm_train_corr_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get attribute's description, order by correlation\n",
    "df_clean_norm_train_meta_sorted = get_df_meta_by_correlation2(\n",
    "    df_clean_norm_train_corr_matrix, \n",
    "    df_clean_norm_train_meta,\n",
    "    target[0])\n",
    "\n",
    "df_clean_norm_train_meta_sorted.head(config_df_row_correlation_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot target to features 1-d pca\n",
    "plot_pca_smarter(df_clean_norm_train, df_clean_norm_train_meta_sorted, target, 19)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Feature engineering\n",
    " ---\n",
    " Select attributes that have the strongest relationship with the target using KBest.\n",
    "\n",
    "\n",
    " [feature_selection](https://machinelearningmastery.com/feature-selection-machine-learning-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect and compare f-scores (all attributes)\n",
    "kbest = SelectKBest(k=len(numeric_attributes), \n",
    "    score_func=f_regression)\n",
    "\n",
    "kbest.fit(df_clean_norm_train[numeric_attributes], \n",
    "    df_clean_norm_train[target[0]]) \n",
    "\n",
    "df_attribute_scores = pd.DataFrame({'attribute': numeric_attributes, 'kbest': kbest.scores_}).sort_values(by='kbest', ascending=False)\n",
    "df_attribute_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_attribute_scores.iloc[0:18, 0]\n",
    "\n",
    "plot_pca_smarter2(df_clean_norm_train, \n",
    "    df_clean_norm_train_meta_sorted, \n",
    "    target, \n",
    "    features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Model engineering\n",
    " ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number_of_features = 38\n",
    "model_validation_size = 0.25\n",
    "model_seed = 2\n",
    "\n",
    "model_iteration_max = 2500\n",
    "model_tollerance = 0.0005\n",
    "model_alpha = 0.1\n",
    "\n",
    "model_cv = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model features, from the top x attributes with highest k-best score\n",
    "features = df_attribute_scores.iloc[0:model_number_of_features, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate data for training and validation works\n",
    "\n",
    "X = df_clean_norm_train[features] \n",
    "y = df_clean_norm_train[target]\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=model_validation_size, \n",
    "    random_state=model_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps = [\n",
    "        ('my_scale', StandardScaler()),\n",
    "        ('my_sgd', SGDRegressor(random_state=model_seed, max_iter=model_iteration_max, tol=model_tollerance, alpha=model_alpha)) \n",
    "            ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    pipeline, \n",
    "    X_train, \n",
    "    y_train.values.ravel(), \n",
    "    cv=model_cv, \n",
    "    verbose=False, \n",
    "    return_train_score=True, \n",
    "    return_estimator=True)\n",
    "\n",
    "cv_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model with highest validation score ('test_score')\n",
    "model = cv_results['estimator'][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curve\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(model,\n",
    "    X_train, \n",
    "    y_train.values.ravel(), \n",
    "    cv=model_cv)\n",
    "\n",
    "# Create means and standard deviations\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Draw lines\n",
    "plt.plot(train_sizes, train_mean, '--', label=\"Training score\")\n",
    "plt.plot(train_sizes, val_mean, label=\"Cross-validation score\")\n",
    "\n",
    "# Draw bands\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, color=\"#DDDDDD\")\n",
    "\n",
    "# Create plot\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction \n",
    "y_pred = model.predict(X_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute model evaluation metrices\n",
    "\n",
    "mse = mean_squared_error(y_validation, y_pred)\n",
    "mae = mean_absolute_error(y_validation, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_validation, y_pred)\n",
    "\n",
    "result = {\n",
    "    'metric': ['MSE', 'MAE', 'RMSE', 'R2'], \n",
    "    'value': [mse, mae, rmse, r2]\n",
    "}\n",
    "\n",
    "pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune learning rate\n",
    "\n",
    "tuning_param_grid = {\n",
    "}\n",
    "\n",
    "tuning_pipeline = Pipeline(\n",
    "    steps = [\n",
    "        ('my_scale', StandardScaler()),\n",
    "        ('my_sgd', SGDRegressor(random_state=model_seed, max_iter=model_iteration_max, tol=model_tollerance, alpha=model_alpha)) \n",
    "            ])\n",
    "\n",
    "tuning_cv_results = cross_validate(\n",
    "    tuning_pipeline, \n",
    "    X_train, \n",
    "    y_train.values.ravel(), \n",
    "    cv=model_cv, \n",
    "    verbose=False, \n",
    "    return_train_score=True, \n",
    "    return_estimator=True)\n",
    "\n",
    "tuning_model = tuning_cv_results['estimator'][0]\n",
    "\n",
    "clf = GridSearchCV(tuning_model, tuning_param_grid, n_jobs=4)\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(\"Best score: \" + str(clf.best_score_))\n",
    "print(clf.best_params_)\n",
    "#pd.DataFrame(clf.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot validation data - predicited + actual result\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "size = 275 # y_validation.size\n",
    "\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(30)\n",
    "\n",
    "ax.scatter(x = range(0, size), y=y_validation[0:size], c = 'blue', label = 'pred', alpha = 0.5)\n",
    "ax.scatter(x = range(0, size), y=y_pred[0:size], c = 'red', label = 'act', alpha = 0.5)\n",
    "plt.title('Actual and predicted values')\n",
    "plt.xlabel('Observations')\n",
    "plt.ylabel('price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot validation data - predicited + actual result\n",
    "\n",
    "diff = y_validation[0:y_pred.size]['SalePrice'] - y_pred[:,]\n",
    "diff.hist(bins = 40)\n",
    "plt.title('Histogram of prediction errors')\n",
    "plt.xlabel('Price prediction error')\n",
    "plt.ylabel('Frequency')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0, 450000], [0, 450000], '--r')\n",
    "plt.scatter(y_validation[0:size], y_pred[0:size])\n",
    "\n",
    "plt.xlabel('Prediction', size=15)\n",
    "plt.ylabel('Actual', size=15)\n",
    "plt.tick_params(axis='x')\n",
    "plt.tick_params(axis='y')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model result\n",
    "\n",
    "print(model.named_steps['my_sgd'].intercept_)\n",
    "\n",
    "result = {\n",
    "    'feature': features,\n",
    "    'coef': model.named_steps['my_sgd'].coef_\n",
    "}\n",
    "\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... test data\n",
    "\n",
    "X_test = df_clean_norm_test[features]\n",
    "X_test.loc[:, 'Id'] = df_clean_norm_test.loc[:, 'Id']\n",
    "\n",
    "#X_test.reset_index(drop=True, inplace=True)\n",
    "X_test.set_index(\"Id\", drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction - use model with highest validation score ('test_score')\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "res = X_test\n",
    "res['SalePrice'] = y_pred\n",
    "\n",
    "# create submission file\n",
    "z = res.reset_index()\n",
    "zz = z[['Id', 'SalePrice']].sort_values(by='Id', ascending=True, na_position='first').reset_index()\n",
    "zz[['Id', 'SalePrice']].to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
